{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16a78ce4-37be-413a-949b-7cd8409f0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import visualkeras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39818548-bfaf-45e1-a07c-dc259ab7bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and preprocess MNIST\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), 28*28))\n",
    "x_test  = x_test.reshape((len(x_test),  28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abf045aa-a01c-4ec0-befb-d465082ee2be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist_feedforward.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m summary(autoencoder)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "# 2. Build the autoencoder model\n",
    "input_img = Input(shape=(784,))\n",
    "x = Dense(1024, activation='relu')(input_img)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(8, activation='relu')(x)\n",
    "encoded   = Dense(2, activation='sigmoid')(x)   # Encoded representation (dimension reduction)\n",
    "y = Dense(8, activation='relu')(encoded)\n",
    "y = Dense(64, activation='relu')(y)\n",
    "y = Dense(256, activation='relu')(y)\n",
    "y = Dense(1024, activation='relu')(y)\n",
    "decoded   = Dense(784, activation='sigmoid')(y) # Output layer\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.save('mnist_feedforward.keras')\n",
    "summary(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ee3c2-73b6-4a20-910b-9378226edc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train the autoencoder (just a few epochs for demo)\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "# 4. Visualize the model architecture\n",
    "img = visualkeras.layered_view(\n",
    "    autoencoder,  \n",
    "    to_file=None, \n",
    "    scale_xy=2, \n",
    "    scale_z=1, \n",
    "    max_z=6,  # thin Z-stacking for shallow net\n",
    "    draw_volume=False,  # option: True for more 3D look\n",
    ")\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fd973a3-4236-456a-8326-e619f838354b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 16:58:45.755569: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2025-11-05 16:58:45.755587: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2025-11-05 16:58:45.767246: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2025-11-05 16:58:45.767569: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Set a folder to store logs (each run should have a unique folder)\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "writer = tf.summary.create_file_writer('logs/graph_architecture')\n",
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "# Call your model once to \"build\" it\n",
    "autoencoder(np.zeros((1,784)))\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(\n",
    "        name=\"autoencoder_trace\",\n",
    "        step=0,\n",
    "        profiler_outdir='logs/graph_architecture'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a74535de-6517-470e-9c51-07fa5f456f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manual_autoencoder_custom_colors.png'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "# Layer definitions: (name, shape, units, activation)\n",
    "layer_data = [\n",
    "    ('Input', 'oval', 784, ''),\n",
    "    ('Dense1', 'box', 1024, 'relu'),\n",
    "    ('Dense2', 'box', 256, 'relu'),\n",
    "    ('Dense3', 'box', 64, 'relu'),\n",
    "    ('Dense4', 'box', 8, 'relu'),\n",
    "    ('Bottleneck', 'ellipse', 2, 'sigmoid'),\n",
    "    ('Dense5', 'box', 8, 'relu'),\n",
    "    ('Dense6', 'box', 64, 'relu'),\n",
    "    ('Dense7', 'box', 256, 'relu'),\n",
    "    ('Dense8', 'box', 1024, 'relu'),\n",
    "    ('Output', 'oval', 784, 'sigmoid'),\n",
    "]\n",
    "\n",
    "# Explicit color assignments\n",
    "input_output_color = \"#4285F4\"   # Blue\n",
    "bottleneck_color   = \"#9874C5\"   # Purple\n",
    "\n",
    "dense_colors = {\n",
    "    'Dense1': \"#34A853\",    # Green\n",
    "    'Dense2': \"#FBBC05\",    # Yellow\n",
    "    'Dense3': \"#FFA500\",    # Orange\n",
    "    'Dense4': \"#EA4335\",    # Red\n",
    "    'Dense5': \"#EA4335\",    # Red          # symmetric with Dense4\n",
    "    'Dense6': \"#FFA500\",    # Orange       # symmetric with Dense3\n",
    "    'Dense7': \"#FBBC05\",    # Yellow       # symmetric with Dense2\n",
    "    'Dense8': \"#34A853\",    # Green        # symmetric with Dense1\n",
    "}\n",
    "\n",
    "# Scaling height based on number of units\n",
    "max_units = max(layer[2] for layer in layer_data)\n",
    "min_units = min(layer[2] for layer in layer_data)\n",
    "\n",
    "def scale_height(units, scale_min=0.7, scale_max=2.5):\n",
    "    if max_units == min_units:\n",
    "        return (scale_min + scale_max) / 2\n",
    "    return scale_min + (scale_max - scale_min) * (units - min_units) / (max_units - min_units)\n",
    "\n",
    "fixed_width = '0.2'  # inches\n",
    "\n",
    "dot = Digraph('Autoencoder', format='png')\n",
    "dot.attr(rankdir='LR', dpi='300', size='14,5')\n",
    "\n",
    "# Draw nodes\n",
    "for idx, (name, shape, units, activation) in enumerate(layer_data):\n",
    "    label = f'{name}\\n{units}'\n",
    "    if activation:\n",
    "        label += f'\\n{activation}'\n",
    "    height = str(round(scale_height(units), 2))\n",
    "    if name == 'Input' or name == 'Output':\n",
    "        fillcolor = input_output_color\n",
    "    elif name == 'Bottleneck':\n",
    "        fillcolor = bottleneck_color\n",
    "    else:\n",
    "        fillcolor = dense_colors[name]\n",
    "    dot.node(\n",
    "        name,\n",
    "        label=label,\n",
    "        shape=shape,\n",
    "        width=fixed_width,\n",
    "        height=height,\n",
    "        style='filled',\n",
    "        fillcolor=fillcolor\n",
    "    )\n",
    "\n",
    "# Draw edges\n",
    "for i in range(len(layer_data) - 1):\n",
    "    dot.edge(layer_data[i][0], layer_data[i+1][0])\n",
    "\n",
    "dot.render('manual_autoencoder_custom_colors', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a1eaeb-b2dc-4d0f-9889-737a9c09bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: node 'bottleneck', graph 'Autoencoder' size too small for label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'autoencoder_vertical.png'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph('Autoencoder', format='png')\n",
    "dot.attr(rankdir='TB', splines='ortho', bgcolor='white')\n",
    "dot.attr('node', fontname='Helvetica', fontsize='18', style='filled', color='gray70')\n",
    "\n",
    "dot.node('input',      'Input',  shape='rect', width='2.2', height='0.7', fillcolor='#99ccff', penwidth='2', fixedsize='true')\n",
    "dot.node('output',     'Output', shape='rect', width='2.2', height='0.7', fillcolor='#99ccff', penwidth='2', fixedsize='true')\n",
    "\n",
    "# Encoder trapezoid (polygon, vertical with orientation=0)\n",
    "dot.node('encoder', 'Encoder',\n",
    "         shape='polygon', sides='4',\n",
    "         orientation='0',\n",
    "         distortion='0.35',\n",
    "         width='1.3', height='1.0',\n",
    "         fillcolor='#a0e6a0', penwidth='2', fixedsize='true')\n",
    "\n",
    "# Decoder mirrored trapezoid (polygon, vertical with orientation=90)\n",
    "dot.node('decoder', 'Decoder',\n",
    "         shape='polygon', sides='4',\n",
    "         orientation='180',\n",
    "         distortion='0.35',\n",
    "         width='1.3', height='1.0',\n",
    "         fillcolor='#ffe698', penwidth='2', fixedsize='true')\n",
    "\n",
    "dot.node('bottleneck', 'Bottleneck', shape='square', width='0.55', height='0.55',\n",
    "         fillcolor='#d4bbff', penwidth='2', color='#9874C5', fixedsize='true')\n",
    "\n",
    "dot.edge('input',      'encoder',     penwidth='2', arrowsize='1.3')\n",
    "dot.edge('encoder',    'bottleneck',  penwidth='2', arrowsize='1.3')\n",
    "dot.edge('bottleneck', 'decoder',     penwidth='2', arrowsize='1.3')\n",
    "dot.edge('decoder',    'output',      penwidth='2', arrowsize='1.3')\n",
    "\n",
    "dot.render('autoencoder_vertical', view=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
